{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from bs4 import MarkupResemblesLocatorWarning, XMLParsedAsHTMLWarning, BeautifulSoup\n",
    "import bs4\n",
    "#warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#def extractEpub(filename: str):\n",
    "#  archive = ZipFile(f'input/{filename}')\n",
    "#  archive.extractall(f\"data/{filename}\")\n",
    "#  archive.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extractEpub('Spice and Wolf, Vol. 9.epub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputEpubs = glob.glob('*', root_dir='./input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readAll(filename: str):\n",
    "  file = open(filename, encoding='utf-8')\n",
    "  text = file.read()\n",
    "  file.close()\n",
    "  return text\n",
    "\n",
    "def writeAll(filename: str, text: str):\n",
    "  file = open(filename, encoding='utf-8', mode='w')\n",
    "  text = file.write(text)\n",
    "  return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "\n",
    "#for volume in dataFolders:\n",
    "#  htmlFiles = glob.glob(f\"{volume}\\\\*.html\")\n",
    "#\n",
    "#  testFile = htmlFiles[0]\n",
    "#  #print(testFile)\n",
    "#  hehe = BeautifulSoup(readAll(testFile), \"html5lib\").contents[1]\n",
    "#\n",
    "#  writeAll(f'{volume}/testoutput.html', hehe.prettify())\n",
    "#  paragraphs = hehe.find_next('body')\n",
    "#  for v in paragraphs:\n",
    "#   print(v)\n",
    "#\n",
    "#  #for v in hehe:\n",
    "#  #  #print(v)\n",
    "#  #  print('helo')\n",
    "#  ##print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from bs4 import NavigableString, Tag\n",
    "\n",
    "def calculateIndex(value: int):\n",
    "  #if value < 4:\n",
    "  #  return value // 2 + 1\n",
    "  #if value == 1:\n",
    "  #  return 1\n",
    "  #if value == 2:\n",
    "  #  return 1\n",
    "  #if value == 3:\n",
    "  #  return 1\n",
    "  #if value == 4:\n",
    "  #  return 2\n",
    "  #if value == 5:\n",
    "  #  return 2\n",
    "  #if value == 6:\n",
    "  #  return 3\n",
    "  return value // 3 + 1\n",
    "\n",
    "\n",
    "def parseText(soup: BeautifulSoup, text: str):\n",
    "  def embolden(t: str):\n",
    "    dividerIndex = len(t) // 3 + 1\n",
    "    boldPart = soup.new_tag('b')\n",
    "    boldPart.string = t[0: dividerIndex]\n",
    "\n",
    "    return [boldPart, soup.new_string(t[dividerIndex:])]\n",
    "\n",
    "  result : List[Tag | NavigableString] = []\n",
    "\n",
    "  startI = 0\n",
    "  while startI < len(text):\n",
    "    char = text[startI]\n",
    "    if not char.isalpha():\n",
    "      result.append(char)\n",
    "      startI += 1\n",
    "      continue;\n",
    "\n",
    "    if char == '\\'' or char == '\"':\n",
    "      result.extend(embolden(char))\n",
    "      startI += 1\n",
    "      continue;\n",
    "\n",
    "    endI = startI\n",
    "    while endI < len(text) and text[endI].isalpha():\n",
    "      endI += 1\n",
    "\n",
    "    word = text[startI: endI]\n",
    "\n",
    "    result.extend(embolden(word))\n",
    "    startI = endI\n",
    "  return result\n",
    "\n",
    "#result = parseText(BeautifulSoup(), 'hello how are you? ?e')\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, Iterator\n",
    "\n",
    "from bs4 import PageElement\n",
    "\n",
    "def skip(iter: Iterator, count: int):\n",
    "  for i in range(0, count):\n",
    "    try:\n",
    "      iter.__next__()\n",
    "    except StopIteration:\n",
    "      return\n",
    "\n",
    "def parseTree(soup: BeautifulSoup, elements: Iterable[PageElement]):\n",
    "  iter = elements.__iter__()\n",
    "  while True:\n",
    "    try:\n",
    "      next = iter.__next__()\n",
    "\n",
    "      if next.string is None:\n",
    "        parseTree(soup, next.children)\n",
    "      else:\n",
    "        boldText = parseText(soup, next.string)\n",
    "        next.replace_with(*boldText)\n",
    "        skip(iter, len(boldText) - 1)\n",
    "\n",
    "    except StopIteration:\n",
    "      break;\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator\n",
    "\n",
    "\n",
    "def cleanupText(text: str):\n",
    "  return text.replace('\\n', '')\n",
    "\n",
    "#page = BeautifulSoup(cleanupText(\"\"\"\n",
    "#<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"\" xml:lang=\"\">\n",
    "#<body>\n",
    "#hello there\n",
    "#<p class=\"calibre1\"><a id=\"p10\"></a><a href=\"#p12\">Copyright</a></p>\n",
    "#<p class=\"calibre1\">SPICE AND WOLF, Volume 9: The Town of Strife II</p>\n",
    "#</body>\n",
    "#</html>\n",
    "#                     \"\"\"), \"html5lib\")\n",
    "\n",
    "\n",
    "#paths = ['./data/Spice and Wolf, Vol. 9.epub/index_split_000.html', './data/Spice and Wolf, Vol. 9.epub/index_split_001.html', './data/Spice and Wolf, Vol. 9.epub/index_split_002.html']\n",
    "#\n",
    "#for path in paths:\n",
    "#  page = BeautifulSoup(readAll(path), 'html5lib')\n",
    "#\n",
    "#\n",
    "#  iter = page.children.__iter__()\n",
    "#\n",
    "#  parseTree(page, page.children)\n",
    "#\n",
    "#  #print(page.prettify())\n",
    "#\n",
    "#  writeAll(path, str(page))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import ebooklib\n",
    "from ebooklib import epub\n",
    "from ebooklib.epub import EpubHtml\n",
    "\n",
    "\n",
    "def convertBook(filename: str):\n",
    "  book = epub.read_epub(f'./input/{filename}')\n",
    "  book.set_title(book.title + 'bold')\n",
    "  print(book.title)\n",
    "\n",
    "  for document in book.get_items_of_type(ebooklib.ITEM_DOCUMENT):\n",
    "    print(type(document))\n",
    "    document : EpubHtml = document\n",
    "    documentStr = str(document.content, encoding='utf-8')\n",
    "    hehe = BeautifulSoup(documentStr, 'xml')\n",
    "    parseTree(hehe, hehe.children)\n",
    "    document.content = bytes(str(hehe), 'utf-8')\n",
    "    #print(type(document.content))\n",
    "\n",
    "  epub.write_epub(f'./output/{filename}', book)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anoromg\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ebooklib\\epub.py:1395: UserWarning: In the future version we will turn default option ignore_ncx to True.\n",
      "  warnings.warn('In the future version we will turn default option ignore_ncx to True.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spice and Wolf, Vol. 10bold\n",
      "<class 'ebooklib.epub.EpubHtml'>\n",
      "<class 'ebooklib.epub.EpubHtml'>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m book \u001b[38;5;129;01min\u001b[39;00m inputEpubs:\n\u001b[0;32m      2\u001b[0m \t\u001b[38;5;66;03m#print(book)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m   \u001b[43mconvertBook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbook\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 16\u001b[0m, in \u001b[0;36mconvertBook\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     14\u001b[0m documentStr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(document\u001b[38;5;241m.\u001b[39mcontent, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m hehe \u001b[38;5;241m=\u001b[39m BeautifulSoup(documentStr, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m \u001b[43mparseTree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhehe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhehe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchildren\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m document\u001b[38;5;241m.\u001b[39mcontent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytes\u001b[39m(\u001b[38;5;28mstr\u001b[39m(hehe), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m#print(type(document.content))\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[10], line 19\u001b[0m, in \u001b[0;36mparseTree\u001b[1;34m(soup, elements)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mnext\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__next__\u001b[39m()\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mnext\u001b[39m\u001b[38;5;241m.\u001b[39mstring \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 19\u001b[0m   \u001b[43mparseTree\u001b[49m\u001b[43m(\u001b[49m\u001b[43msoup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchildren\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     21\u001b[0m   boldText \u001b[38;5;241m=\u001b[39m parseText(soup, \u001b[38;5;28mnext\u001b[39m\u001b[38;5;241m.\u001b[39mstring)\n",
      "Cell \u001b[1;32mIn[10], line 19\u001b[0m, in \u001b[0;36mparseTree\u001b[1;34m(soup, elements)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mnext\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__next__\u001b[39m()\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mnext\u001b[39m\u001b[38;5;241m.\u001b[39mstring \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 19\u001b[0m   \u001b[43mparseTree\u001b[49m\u001b[43m(\u001b[49m\u001b[43msoup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchildren\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     21\u001b[0m   boldText \u001b[38;5;241m=\u001b[39m parseText(soup, \u001b[38;5;28mnext\u001b[39m\u001b[38;5;241m.\u001b[39mstring)\n",
      "Cell \u001b[1;32mIn[10], line 22\u001b[0m, in \u001b[0;36mparseTree\u001b[1;34m(soup, elements)\u001b[0m\n\u001b[0;32m     20\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     21\u001b[0m     boldText \u001b[38;5;241m=\u001b[39m parseText(soup, \u001b[38;5;28mnext\u001b[39m\u001b[38;5;241m.\u001b[39mstring)\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;43mnext\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace_with\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mboldText\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     skip(\u001b[38;5;28miter\u001b[39m, \u001b[38;5;28mlen\u001b[39m(boldText) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Anoromg\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\bs4\\element.py:313\u001b[0m, in \u001b[0;36mPageElement.replace_with\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    311\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot replace a Tag with its parent.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    312\u001b[0m old_parent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m--> 313\u001b[0m my_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract(_self_index\u001b[38;5;241m=\u001b[39mmy_index)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, replace_with \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(args, start\u001b[38;5;241m=\u001b[39mmy_index):\n",
      "File \u001b[1;32mc:\\Users\\Anoromg\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\bs4\\element.py:1539\u001b[0m, in \u001b[0;36mTag.index\u001b[1;34m(self, element)\u001b[0m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Find the index of a child by identity, not value.\u001b[39;00m\n\u001b[0;32m   1532\u001b[0m \n\u001b[0;32m   1533\u001b[0m \u001b[38;5;124;03mAvoids issues with tag.contents.index(element) getting the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;124;03m:param element: Look for this PageElement in `self.contents`.\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, child \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontents):\n\u001b[1;32m-> 1539\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m element:\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m i\n\u001b[0;32m   1541\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTag.index: element not in tag\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for book in inputEpubs:\n",
    "\t#print(book)\n",
    "  convertBook(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('hello', 'there')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#writeAll(f'{volume}/testoutput.html', page.prettify())\n",
    "#paragraphs = hehe.find_next('body')\n",
    "#print(list(paragraphs.descendants))\n",
    "#print(paragraphs.descendants)\n",
    "#iterator = paragraphs.__iter__()\n",
    "#print(list(paragraphs.children))\n",
    "#hello = iterator.__next__()\n",
    "##hello = list(paragraphs.children)[0]\n",
    "#b1 = hehe.new_tag('b')\n",
    "#b1.string = hello.text + '1'\n",
    "#\n",
    "#b2 = hehe.new_tag('b')\n",
    "#b2.string = hello.text + '2'\n",
    "#\n",
    "#hello.replaceWith(*[b1, b2])\n",
    "#next = iterator.__next__()\n",
    "#print(type(next))\n",
    "#if next.name != 'b':\n",
    "#  print('keke')\n",
    "#paragraphs.\n",
    "#print(list(paragraphs.children))\n",
    "#for v in paragraphs:\n",
    "#  print(v.text)\n",
    "#  print(v)\n",
    "\n",
    "#for v in hehe:\n",
    "#  #print(v)\n",
    "#  print('helo')\n",
    "##print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spice and Wolf, Vol. 10bold\n",
      "<class 'ebooklib.epub.EpubHtml'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import ebooklib\n",
    "from ebooklib import epub\n",
    "from ebooklib.epub import EpubHtml\n",
    "import re\n",
    "\n",
    "\n",
    "def testBook(filename: str):\n",
    "  book = epub.read_epub(f'./input/{filename}')\n",
    "  book.set_title(book.title + 'bold')\n",
    "  print(book.title)\n",
    "\n",
    "  document = list(book.get_items_of_type(ebooklib.ITEM_DOCUMENT))[1]\n",
    "  print(type(document))\n",
    "  document : EpubHtml = document\n",
    "  documentStr = str(document.get_body_content(), encoding='utf-8')\n",
    "  hehe = BeautifulSoup(documentStr, 'xml')\n",
    "\n",
    "  parseTree(hehe, hehe.children)\n",
    "  text = hehe.prettify()\n",
    "\n",
    "  #pattern = re.compile(\"<.+>\")\n",
    "  #result = pattern.match(text)\n",
    "  skippedText = \"<?xml version=\\\"1.0\\\" encoding=\\\"utf-8\\\"?>\"\n",
    "  result = text.find(skippedText)\n",
    "  if result != -1:\n",
    "    text = text[result + len(skippedText):]\n",
    "  #print(text)\n",
    "  document.set_content(bytes(text, 'utf-8'))\n",
    "  print(hehe.prettify())\n",
    "  #document.content = bytes(hehe.prettify(), 'utf-8')\n",
    "  print(str(document.content))\n",
    "  print(type(document.content))\n",
    "\n",
    "  #epub.write_epub(f'./output/test-{filename}', book)\n",
    "\n",
    "\n",
    "\n",
    "testBook('Spice and Wolf, Vol. 10.epub')\n",
    "\n",
    "\n",
    "\n",
    "#soup = BeautifulSoup('''\n",
    "#<?xml version='1.0' encoding='utf-8'?>\n",
    "#<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"\" xml:lang=\"\">\n",
    "#  <head>\n",
    "#    <title>Spice and Wolf, Vol. 10</title>\n",
    "#    <meta name=\"generator\" content=\"pdftohtml 0.36\"/>\n",
    "#    <meta name=\"author\" content=\"Isuna Hasekura &amp; Jyuu Ayakura\"/>\n",
    "#    <meta name=\"date\" content=\"2023-01-23T17:57:18+00:00\"/>\n",
    "#    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\"/>\n",
    "#  <link rel=\"stylesheet\" type=\"text/css\" href=\"stylesheet.css\"/>\n",
    "#<link rel=\"stylesheet\" type=\"text/css\" href=\"page_styles.css\"/>\n",
    "#</head>\n",
    "#  <body class=\"calibre\">\n",
    "#  </body>\n",
    "#  </html>\n",
    "#                     ''', 'xml')\n",
    "#\n",
    "#\n",
    "#print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
